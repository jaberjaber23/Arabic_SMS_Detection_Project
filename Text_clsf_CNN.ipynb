{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nnq2trgcQ5Oq"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O8dM4dVMcxWV"
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "P3JM7JiPc3d5",
    "outputId": "165ee4fe-1f4c-4416-d068-b8bb94763992"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ذهاب', 'جورونج', 'نقط', 'مجنو', 'استفاد', 'ب...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['طيب', 'نكت', 'لار']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['دخول', 'مجا', '٢', 'كاس', 'اتحاد', 'نهاء', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['اقول', 'وقت', 'مبكر', 'هور']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['ناه', 'اعتقد', 'جو', 'اوسف', 'عيش', 'حول', '...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sms  label\n",
       "0  ['ذهاب', 'جورونج', 'نقط', 'مجنو', 'استفاد', 'ب...      0\n",
       "1                              ['طيب', 'نكت', 'لار']      0\n",
       "2  ['دخول', 'مجا', '٢', 'كاس', 'اتحاد', 'نهاء', '...      1\n",
       "3                     ['اقول', 'وقت', 'مبكر', 'هور']      0\n",
       "4  ['ناه', 'اعتقد', 'جو', 'اوسف', 'عيش', 'حول', '...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "Vc3VrV6ifqEW",
    "outputId": "f3710971-22a3-4b76-9271-2b14c5cc66a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Conda\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Number of ham and spam messages')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df.label)\n",
    "plt.xlabel('label')\n",
    "plt.title('Number of ham and spam messages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "17TKrsK4fuyZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X = df.v2\\nY = df.v1\\nle = LabelEncoder()\\nY = le.fit_transform(Y)\\nY = Y.reshape(-1,1)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''X = df.v2\n",
    "Y = df.v1\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "Y = Y.reshape(-1,1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['sms']\n",
    "Y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "okAPlrf4fweY"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N9p1eQ3hzeUS"
   },
   "source": [
    "# Data processing \n",
    "* Tokenize the data\n",
    "* Padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "0FxvVIP4c5k2",
    "outputId": "08a183b3-6264-4eac-e311-2d9154d8749f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tags = df.label\n",
    "texts = df.sms\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from keras import metrics\n",
    "print('import done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bAh4pQM7d9BH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(5113,) (5113, 1000)\n"
     ]
    }
   ],
   "source": [
    "num_max = 1000\n",
    "# preprocess\n",
    "le = LabelEncoder()\n",
    "tags = le.fit_transform(tags)\n",
    "tok = Tokenizer(num_words=num_max)\n",
    "tok.fit_on_texts(texts)\n",
    "mat_texts = tok.texts_to_matrix(texts,mode='count')\n",
    "print(tags[:5])\n",
    "print(mat_texts[:5])\n",
    "print(tags.shape,mat_texts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NW0ived4eHdI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               512512    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 644,097\n",
      "Trainable params: 644,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "compile done\n",
      "Train on 4090 samples, validate on 1023 samples\n",
      "Epoch 1/10\n",
      "4090/4090 [==============================] - 1s 341us/sample - loss: 0.2572 - acc: 0.9147 - binary_accuracy: 0.9147 - val_loss: 0.1080 - val_acc: 0.9629 - val_binary_accuracy: 0.9629\n",
      "Epoch 2/10\n",
      " 448/4090 [==>...........................] - ETA: 0s - loss: 0.0937 - acc: 0.9621 - binary_accuracy: 0.9621"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Conda\\lib\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4090/4090 [==============================] - 1s 155us/sample - loss: 0.0867 - acc: 0.9746 - binary_accuracy: 0.9746 - val_loss: 0.1070 - val_acc: 0.9677 - val_binary_accuracy: 0.9677\n",
      "Epoch 3/10\n",
      "4090/4090 [==============================] - 1s 141us/sample - loss: 0.0449 - acc: 0.9861 - binary_accuracy: 0.9861 - val_loss: 0.1197 - val_acc: 0.9707 - val_binary_accuracy: 0.9707\n",
      "Epoch 4/10\n",
      "4090/4090 [==============================] - 1s 139us/sample - loss: 0.0306 - acc: 0.9897 - binary_accuracy: 0.9897 - val_loss: 0.1515 - val_acc: 0.9619 - val_binary_accuracy: 0.9619\n",
      "Epoch 5/10\n",
      "4090/4090 [==============================] - 1s 144us/sample - loss: 0.0248 - acc: 0.9934 - binary_accuracy: 0.9934 - val_loss: 0.1944 - val_acc: 0.9599 - val_binary_accuracy: 0.9599\n",
      "Epoch 6/10\n",
      "4090/4090 [==============================] - 1s 125us/sample - loss: 0.0227 - acc: 0.9939 - binary_accuracy: 0.9939 - val_loss: 0.1738 - val_acc: 0.9648 - val_binary_accuracy: 0.9648\n",
      "Epoch 7/10\n",
      "4090/4090 [==============================] - 0s 119us/sample - loss: 0.0192 - acc: 0.9944 - binary_accuracy: 0.9944 - val_loss: 0.2022 - val_acc: 0.9629 - val_binary_accuracy: 0.9629\n",
      "Epoch 8/10\n",
      "4090/4090 [==============================] - 0s 119us/sample - loss: 0.0181 - acc: 0.9949 - binary_accuracy: 0.9949 - val_loss: 0.1867 - val_acc: 0.9589 - val_binary_accuracy: 0.9589\n",
      "Epoch 9/10\n",
      "4090/4090 [==============================] - 1s 140us/sample - loss: 0.0174 - acc: 0.9954 - binary_accuracy: 0.9954 - val_loss: 0.2028 - val_acc: 0.9619 - val_binary_accuracy: 0.9619\n",
      "Epoch 10/10\n",
      "4090/4090 [==============================] - 1s 142us/sample - loss: 0.0178 - acc: 0.9956 - binary_accuracy: 0.9956 - val_loss: 0.2372 - val_acc: 0.9580 - val_binary_accuracy: 0.9580\n"
     ]
    }
   ],
   "source": [
    "def get_simple_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(num_max,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc',metrics.binary_accuracy])\n",
    "    print('compile done')\n",
    "    return model\n",
    "\n",
    "def check_model(model,x,y):\n",
    "    model.fit(x,y,batch_size=32,epochs=10,verbose=1,validation_split=0.2)\n",
    "\n",
    "m = get_simple_model()\n",
    "check_model(m,mat_texts,tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "odfOHWhnzyp3"
   },
   "source": [
    "# **CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "NcVhv-h4eMIN",
    "outputId": "450f583e-903f-41d3-d218-69459a0b4436"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 239, 813, 734, 274, 100, 960, 11, 142]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  42 239 813 734 274 100 960  11 142]\n",
      "(5113, 100)\n"
     ]
    }
   ],
   "source": [
    "# for cnn preproces\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "max_len = 100\n",
    "cnn_texts_seq = tok.texts_to_sequences(texts)\n",
    "print(cnn_texts_seq[0])\n",
    "cnn_texts_mat = pad_sequences(cnn_texts_seq,maxlen=max_len)\n",
    "print(cnn_texts_mat[0])\n",
    "print(cnn_texts_mat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DE_g1jkGz2iN"
   },
   "source": [
    "**Model v1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "nfSutYJyefnB",
    "outputId": "aa961175-c5fc-4446-9084-61d8746733f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Conda\\lib\\site-packages\\keras\\initializers\\initializers_v1.py:297: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 20)           20000     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100, 20)           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 98, 64)            3904      \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 64)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,801\n",
      "Trainable params: 40,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4090 samples, validate on 1023 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "def get_cnn_model_v1():   \n",
    "    model = Sequential()\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    # 1000 is num_max\n",
    "    model.add(Embedding(1000,\n",
    "                        20,\n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(64,\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc',metrics.binary_accuracy])\n",
    "    return model\n",
    "\n",
    "m = get_cnn_model_v1()\n",
    "check_model(m,cnn_texts_mat,tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IFrA4doPz8r_"
   },
   "source": [
    "**Model v2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "kG9UMVHxejtc",
    "outputId": "f0260f8b-5e20-4929-88c0-74b0c1581fb9"
   },
   "outputs": [],
   "source": [
    "def get_cnn_model_v2(): # added embed   \n",
    "    model = Sequential()\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    # 1000 is num_max\n",
    "    model.add(Embedding(1000,\n",
    "                        50, #!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(64,\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc',metrics.binary_accuracy])\n",
    "    return model\n",
    "\n",
    "m = get_cnn_model_v2()\n",
    "check_model(m,cnn_texts_mat,tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r1KnWIz40EAy"
   },
   "source": [
    "**Model v3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "4OFK4njgg729",
    "outputId": "30f93e5d-0576-40d5-ec71-e1e3bf6b375b"
   },
   "outputs": [],
   "source": [
    "def get_cnn_model_v3():    # added filter\n",
    "    model = Sequential()\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    # 1000 is num_max\n",
    "    model.add(Embedding(1000,\n",
    "                        20,\n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(256, #!!!!!!!!!!!!!!!!!!!\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc',metrics.binary_accuracy])\n",
    "    return model\n",
    "\n",
    "m = get_cnn_model_v3()\n",
    "check_model(m,cnn_texts_mat,tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fOnHHHsT0OHL"
   },
   "source": [
    "**Test data processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bz34TFwafZty"
   },
   "outputs": [],
   "source": [
    " test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-BgmXc8i0T60"
   },
   "source": [
    "**Test data evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NrQ-YDbQf9fF",
    "outputId": "53cda7f8-b65b-4a39-93c1-e5d81193ff40"
   },
   "outputs": [],
   "source": [
    "accr = m.evaluate(test_sequences_matrix,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ioX2HqQh0bpD"
   },
   "source": [
    "# **Print the final result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "m8CpBvBYf_fV",
    "outputId": "a51577f5-d7b1-474a-8c83-3ef97fc777c7"
   },
   "outputs": [],
   "source": [
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hjrg8ReQgZec"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Text-clsf-CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
